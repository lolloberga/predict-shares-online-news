{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T13:42:35.341628Z",
     "start_time": "2023-06-11T13:42:35.336429Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T13:36:16.429298Z",
     "start_time": "2023-06-11T13:36:15.902210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                                url  timedelta  \\\n0   0  http://mashable.com/2014/09/08/safest-cabbies-...      121.0   \n1   1   http://mashable.com/2013/07/25/3d-printed-rifle/      532.0   \n2   2  http://mashable.com/2013/10/30/digital-dinosau...      435.0   \n3   3  http://mashable.com/2014/08/27/homer-simpson-i...      134.0   \n4   4  http://mashable.com/2013/01/10/creepy-robotic-...      728.0   \n\n   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n0            12.0            1015.0         0.422018               1.0   \n1             9.0             503.0         0.569697               1.0   \n2             9.0             232.0         0.646018               1.0   \n3            12.0             171.0         0.722892               1.0   \n4            11.0             286.0         0.652632               1.0   \n\n   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  ...  \\\n0                  0.545031       10.0             6.0  ...   \n1                  0.737542        9.0             0.0  ...   \n2                  0.748428       12.0             3.0  ...   \n3                  0.867925        9.0             5.0  ...   \n4                  0.800000        5.0             2.0  ...   \n\n   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n0              -0.160714                  -0.50              -0.071429   \n1              -0.157500                  -0.25              -0.100000   \n2              -0.427500                  -1.00              -0.187500   \n3              -0.216667                  -0.25              -0.166667   \n4              -0.251786                  -0.50              -0.100000   \n\n   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n0                 0.0                      0.00                     0.5   \n1                 0.0                      0.00                     0.5   \n2                 0.0                      0.00                     0.5   \n3                 0.4                     -0.25                     0.1   \n4                 0.2                     -0.10                     0.3   \n\n   abs_title_sentiment_polarity   shares  data_channel    weekday  \n0                          0.00   2900.0           bus    tuesday  \n1                          0.00   1300.0          tech   thursday  \n2                          0.00  17700.0     lifestyle  wednesday  \n3                          0.25   1500.0           bus  wednesday  \n4                          0.10   1400.0          tech   thursday  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>timedelta</th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>...</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n      <th>data_channel</th>\n      <th>weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>http://mashable.com/2014/09/08/safest-cabbies-...</td>\n      <td>121.0</td>\n      <td>12.0</td>\n      <td>1015.0</td>\n      <td>0.422018</td>\n      <td>1.0</td>\n      <td>0.545031</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>-0.160714</td>\n      <td>-0.50</td>\n      <td>-0.071429</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>2900.0</td>\n      <td>bus</td>\n      <td>tuesday</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>http://mashable.com/2013/07/25/3d-printed-rifle/</td>\n      <td>532.0</td>\n      <td>9.0</td>\n      <td>503.0</td>\n      <td>0.569697</td>\n      <td>1.0</td>\n      <td>0.737542</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.157500</td>\n      <td>-0.25</td>\n      <td>-0.100000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>1300.0</td>\n      <td>tech</td>\n      <td>thursday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>http://mashable.com/2013/10/30/digital-dinosau...</td>\n      <td>435.0</td>\n      <td>9.0</td>\n      <td>232.0</td>\n      <td>0.646018</td>\n      <td>1.0</td>\n      <td>0.748428</td>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>-0.427500</td>\n      <td>-1.00</td>\n      <td>-0.187500</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>17700.0</td>\n      <td>lifestyle</td>\n      <td>wednesday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>http://mashable.com/2014/08/27/homer-simpson-i...</td>\n      <td>134.0</td>\n      <td>12.0</td>\n      <td>171.0</td>\n      <td>0.722892</td>\n      <td>1.0</td>\n      <td>0.867925</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>-0.216667</td>\n      <td>-0.25</td>\n      <td>-0.166667</td>\n      <td>0.4</td>\n      <td>-0.25</td>\n      <td>0.1</td>\n      <td>0.25</td>\n      <td>1500.0</td>\n      <td>bus</td>\n      <td>wednesday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>http://mashable.com/2013/01/10/creepy-robotic-...</td>\n      <td>728.0</td>\n      <td>11.0</td>\n      <td>286.0</td>\n      <td>0.652632</td>\n      <td>1.0</td>\n      <td>0.800000</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>-0.251786</td>\n      <td>-0.50</td>\n      <td>-0.100000</td>\n      <td>0.2</td>\n      <td>-0.10</td>\n      <td>0.3</td>\n      <td>0.10</td>\n      <td>1400.0</td>\n      <td>tech</td>\n      <td>thursday</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 50 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_csv('../dataset/development.csv')\n",
    "df_eval = pd.read_csv('../dataset/evaluation.csv')\n",
    "\n",
    "df = pd.concat([df_dev, df_eval], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T13:36:17.454410Z",
     "start_time": "2023-06-11T13:36:17.440886Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_preprocessing(df, reduce_df=True):\n",
    "    df_preproc = df.copy()\n",
    "\n",
    "    # one hot encoding\n",
    "    enc = OneHotEncoder()\n",
    "    encoded_df = pd.concat([df_preproc['weekday'], df_preproc['data_channel']], axis=1)\n",
    "    enc.fit(encoded_df)\n",
    "    encoded_df = enc.transform(encoded_df)\n",
    "    additional_columns = enc.get_feature_names_out()\n",
    "    df_preproc[additional_columns] = encoded_df.toarray()\n",
    "    df_preproc.drop(['weekday', 'data_channel', 'url', 'id'], axis = 1, inplace=True)\n",
    "\n",
    "    # drop from feature selection\n",
    "    df_preproc.drop(columns=['n_non_stop_words', 'kw_min_min', 'kw_max_max'], inplace=True)\n",
    "    # remove n_tokens_content less than 0\n",
    "    df_preproc['n_tokens_content'] = np.log(1 + df_preproc['n_tokens_content'])\n",
    "\n",
    "    if reduce_df:\n",
    "        # Remove outliers from kw_avg_avg (we lost another 9% of the dataset)\n",
    "        q1 = df_preproc['kw_avg_avg'].describe()['25%']\n",
    "        q3 = df_preproc['kw_avg_avg'].describe()['75%']\n",
    "        iqr = q3 - q1\n",
    "        min_kw_avg_avg = q1 - 1.5*iqr\n",
    "        max_kw_avg_avg = q3 + 1.5*iqr\n",
    "        df_preproc = df_preproc[(df_preproc.kw_avg_avg < max_kw_avg_avg) & (df_preproc.kw_avg_avg > min_kw_avg_avg)]\n",
    "\n",
    "    # adjust num_imgs, num_self_hrefs, num_videos, num_hrefs\n",
    "    df_preproc['num_imgs'].fillna(df_preproc['num_imgs'].mean(), inplace=True)\n",
    "    df_preproc['num_imgs'] = np.log(1 + df_preproc['num_imgs'])\n",
    "    df_preproc['num_self_hrefs'].fillna(df_preproc['num_self_hrefs'].mean(), inplace=True)\n",
    "    df_preproc['num_self_hrefs'] = np.log(1 + df_preproc['num_self_hrefs'])\n",
    "    df_preproc['num_videos'].fillna(df_preproc['num_videos'].mean(), inplace=True)\n",
    "    df_preproc['num_videos'] = np.log(1 + df_preproc['num_videos'])\n",
    "    df_preproc['num_hrefs'] = np.log(1 + df_preproc['num_hrefs'])\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['n_tokens_title', 'n_tokens_content']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['n_tokens_title', 'n_tokens_content']])\n",
    "    df_preproc[['n_tokens_title', 'n_tokens_content']] = scaled_features\n",
    "\n",
    "    df_preproc['avg_negative_polarity'] = df_preproc['avg_negative_polarity'].abs()\n",
    "\n",
    "    # Since this features has a range between [0, 10], we can apply a min max scaling\n",
    "    df_preproc['num_keywords'] = df.groupby(['data_channel'], sort=False)['num_keywords'].apply(lambda x: x.fillna(x.mean())).reset_index()['num_keywords']\n",
    "    std_scaler = MinMaxScaler().fit(df_preproc[['num_keywords']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['num_keywords']])\n",
    "    df_preproc[['num_keywords']] = scaled_features\n",
    "\n",
    "    if 'shares' in df_preproc:\n",
    "        df_preproc['shares'] = np.log(df_preproc['shares'])\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['kw_avg_max', 'kw_avg_avg', 'kw_avg_min', 'kw_min_avg', 'kw_max_avg', 'kw_max_min', 'kw_min_max']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['kw_avg_max', 'kw_avg_avg', 'kw_avg_min', 'kw_min_avg','kw_max_avg', 'kw_max_min', 'kw_min_max']])\n",
    "    df_preproc[['kw_avg_max', 'kw_avg_avg', 'kw_avg_min', 'kw_min_avg','kw_max_avg', 'kw_max_min', 'kw_min_max']] = scaled_features\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess']])\n",
    "    df_preproc[['self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess']] = scaled_features\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['n_tokens_title', 'n_tokens_content']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['n_tokens_title', 'n_tokens_content']])\n",
    "    df_preproc[['n_tokens_title', 'n_tokens_content']] = scaled_features\n",
    "\n",
    "    is_weekend = []\n",
    "    for _, row in df_preproc.iterrows():\n",
    "        if row['weekday_sunday'] == 1 or row['weekday_saturday'] == 1:\n",
    "            is_weekend.append(1)\n",
    "        else:\n",
    "            is_weekend.append(0)\n",
    "    df_preproc['is_weekend'] = is_weekend\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['timedelta']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['timedelta']])\n",
    "    df_preproc[['timedelta']] = scaled_features\n",
    "\n",
    "    return df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(7917, 7917)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df_dev = final_preprocessing(df_dev)\n",
    "df_working_df_eval = final_preprocessing(df_eval, reduce_df=False)\n",
    "(len(df_working_df_eval), len(df_eval))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T13:36:21.095799Z",
     "start_time": "2023-06-11T13:36:19.370146Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print('MSE: %2.3f' % mse)\n",
    "    return mse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T13:36:21.797082Z",
     "start_time": "2023-06-11T13:36:21.784473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Start with a Randomized Grid search\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T13:46:06.566275Z",
     "start_time": "2023-06-11T13:46:06.560568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X = working_df_dev.drop(columns=[\"shares\"]).values\n",
    "y = working_df_dev[\"shares\"].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.3, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T13:47:26.064283Z",
     "start_time": "2023-06-11T13:47:26.031392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "Process LokyProcess-8:\n",
      "Process LokyProcess-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 473, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 184, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 379, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 473, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 184, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 379, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 625, in __call__\n",
      "    raise WorkerInterrupt() from e\n",
      "joblib.my_exceptions.WorkerInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 430, in _process_worker\n",
      "    exc = _ExceptionWithTraceback(e)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 229, in __init__\n",
      "    tb = traceback.format_exception(type(exc), exc, tb)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 120, in format_exception\n",
      "    return list(TracebackException(\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 533, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 547, in _load_lines\n",
      "    self.__cause__._load_lines()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 543, in _load_lines\n",
      "    frame.line\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/linecache.py\", line 30, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/tokenize.py\", line 392, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 625, in __call__\n",
      "    raise WorkerInterrupt() from e\n",
      "joblib.my_exceptions.WorkerInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 430, in _process_worker\n",
      "    exc = _ExceptionWithTraceback(e)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 229, in __init__\n",
      "    tb = traceback.format_exception(type(exc), exc, tb)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 120, in format_exception\n",
      "    return list(TracebackException(\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 533, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 547, in _load_lines\n",
      "    self.__cause__._load_lines()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 543, in _load_lines\n",
      "    frame.line\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/linecache.py\", line 30, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/tokenize.py\", line 392, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=42.7min\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=10.5min\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time= 2.8min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1800; total time=30.0min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  54.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1600; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1800; total time=24.3min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time=14.9min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time= 6.1min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1600; total time= 5.9min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1800; total time=29.6min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1200; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=27.4min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=1800; total time=43.0min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time= 3.3min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process LokyProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 456, in _process_worker\n",
      "    mem_usage = _get_memory_usage(pid, force_gc=True)\n",
      "  File \"/Users/lorenzo/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 108, in _get_memory_usage\n",
      "    gc.collect()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    974\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m     \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m     gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1768\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1767\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1768\u001B[0m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1769\u001B[0m \u001B[43m    \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1770\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1771\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1772\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    817\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    818\u001B[0m         )\n\u001B[1;32m    819\u001B[0m     )\n\u001B[0;32m--> 821\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    822\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py:997\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    996\u001B[0m     ensure_ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend\n\u001B[0;32m--> 997\u001B[0m     \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabort_everything\u001B[49m\u001B[43m(\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ready\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:586\u001B[0m, in \u001B[0;36mLokyBackend.abort_everything\u001B[0;34m(self, ensure_ready)\u001B[0m\n\u001B[1;32m    584\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001B[39;00m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 586\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    587\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/executor.py:74\u001B[0m, in \u001B[0;36mMemmappingExecutor.terminate\u001B[0;34m(self, kill_workers)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m, kill_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m---> 74\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kill_workers:\n\u001B[1;32m     76\u001B[0m         \u001B[38;5;66;03m# When workers are killed in such a brutal manner, they cannot\u001B[39;00m\n\u001B[1;32m     77\u001B[0m         \u001B[38;5;66;03m# execute the finalizer of their shared memmaps. The refcount of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     83\u001B[0m \n\u001B[1;32m     84\u001B[0m         \u001B[38;5;66;03m# unregister temporary resources from all contexts\u001B[39;00m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:1199\u001B[0m, in \u001B[0;36mProcessPoolExecutor.shutdown\u001B[0;34m(self, wait, kill_workers)\u001B[0m\n\u001B[1;32m   1198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m executor_manager_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m wait:\n\u001B[0;32m-> 1199\u001B[0m     \u001B[43mexecutor_manager_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001B[39;00m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;66;03m# objects that use file descriptors.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1060\u001B[0m, in \u001B[0;36mThread.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1060\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1062\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1080\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1080\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1081\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m rf \u001B[38;5;241m=\u001B[39m RandomForestRegressor()\n\u001B[1;32m      3\u001B[0m rf_random \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(estimator \u001B[38;5;241m=\u001B[39m rf, param_distributions \u001B[38;5;241m=\u001B[39m random_grid, n_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m, cv \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, n_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mrf_random\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(rf_random\u001B[38;5;241m.\u001B[39mbest_score_)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(rf_random\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:884\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    882\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultimetric_:\n\u001B[1;32m    883\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_refit_for_multimetric(first_test_score)\n\u001B[0;32m--> 884\u001B[0m         refit_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit\n\u001B[1;32m    886\u001B[0m \u001B[38;5;66;03m# For multi-metric evaluation, store the best_index_, best_params_ and\u001B[39;00m\n\u001B[1;32m    887\u001B[0m \u001B[38;5;66;03m# best_score_ iff refit is one of the scorer names\u001B[39;00m\n\u001B[1;32m    888\u001B[0m \u001B[38;5;66;03m# In single metric evaluation, refit_metric is \"score\"\u001B[39;00m\n\u001B[1;32m    889\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultimetric_:\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py:769\u001B[0m, in \u001B[0;36mParallel.__exit__\u001B[0;34m(self, exc_type, exc_value, traceback)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type, exc_value, traceback):\n\u001B[0;32m--> 769\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_terminate_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    770\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/parallel.py:799\u001B[0m, in \u001B[0;36mParallel._terminate_backend\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_terminate_backend\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    798\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 799\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:576\u001B[0m, in \u001B[0;36mLokyBackend.terminate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    573\u001B[0m         \u001B[38;5;66;03m# Don't terminate the workers as we want to reuse them in later\u001B[39;00m\n\u001B[1;32m    574\u001B[0m         \u001B[38;5;66;03m# calls, but cleanup the temporary resources that the Parallel call\u001B[39;00m\n\u001B[1;32m    575\u001B[0m         \u001B[38;5;66;03m# created. This 'hack' requires a private, low-level operation.\u001B[39;00m\n\u001B[0;32m--> 576\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_temp_folder_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unlink_temporary_resources\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_id\u001B[49m\n\u001B[1;32m    578\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    581\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_batch_stats()\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:631\u001B[0m, in \u001B[0;36mTemporaryResourcesManager._unlink_temporary_resources\u001B[0;34m(self, context_id)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(temp_folder):\n\u001B[1;32m    628\u001B[0m     resource_tracker\u001B[38;5;241m.\u001B[39mmaybe_unlink(\n\u001B[1;32m    629\u001B[0m         os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(temp_folder, filename), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    630\u001B[0m     )\n\u001B[0;32m--> 631\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_delete_folder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_non_empty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext_id\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/_memmapping_reducer.py:658\u001B[0m, in \u001B[0;36mTemporaryResourcesManager._try_delete_folder\u001B[0;34m(self, allow_non_empty, context_id)\u001B[0m\n\u001B[1;32m    656\u001B[0m temp_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_temp_folders[context_id]\n\u001B[1;32m    657\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 658\u001B[0m     \u001B[43mdelete_folder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    659\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_non_empty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_non_empty\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    661\u001B[0m     \u001B[38;5;66;03m# Now that this folder is deleted, we can forget about it\u001B[39;00m\n\u001B[1;32m    662\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unregister_context(context_id)\n",
      "File \u001B[0;32m~/University/Polito/Data science lab/predict-shares-online-news/venv/lib/python3.9/site-packages/joblib/disk.py:136\u001B[0m, in \u001B[0;36mdelete_folder\u001B[0;34m(folder_path, onerror, allow_non_empty)\u001B[0m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m err_count \u001B[38;5;241m>\u001B[39m RM_SUBDIRS_N_RETRY:\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;66;03m# the folder cannot be deleted right now. It maybe\u001B[39;00m\n\u001B[1;32m    133\u001B[0m         \u001B[38;5;66;03m# because some temporary files have not been deleted\u001B[39;00m\n\u001B[1;32m    134\u001B[0m         \u001B[38;5;66;03m# yet.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m--> 136\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRM_SUBDIRS_RETRY_TIME\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=3, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T15:14:35.427015Z",
     "start_time": "2023-06-11T13:47:31.937192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rms = mean_squared_error(y_valid, rf_random.predict(X_valid), squared=False)\n",
    "print(rms)\n",
    "r2 = r2_score(y_valid, rf_random.predict(X_valid))\n",
    "adj_r2 = 1-(1-r2)*(len(X_valid) - 1)/(len(X_valid) - X_valid.shape[1] - 1)\n",
    "print(adj_r2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the best_params of the RandomizedSearchCV we should be able to narrow the range of values for each hyperparameter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rms = mean_squared_error(y_valid, gs.predict(X_valid), squared=False)\n",
    "print(rms)\n",
    "r2 = r2_score(y_valid, gs.predict(X_valid))\n",
    "adj_r2 = 1-(1-r2)*(len(X_valid) - 1)/(len(X_valid) - X_valid.shape[1] - 1)\n",
    "print(adj_r2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate final CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = working_df_dev.drop(columns=[\"shares\"]).values\n",
    "y = working_df_dev[\"shares\"].values\n",
    "\n",
    "best_model = RandomForestRegressor(**gs.best_params_)\n",
    "best_model.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make final predictions\n",
    "y_pred = best_model.predict(df_working_df_eval.values)\n",
    "final_preds = np.exp(y_pred)\n",
    "# Write CSV\n",
    "id_col = df_eval['id']\n",
    "new_df = pd.DataFrame(columns=['Id', 'Predicted'])\n",
    "new_df['Id'] = id_col\n",
    "new_df['Predicted'] = final_preds\n",
    "print(new_df.describe())\n",
    "new_df.to_csv('../output/NAME.csv', columns=['Id','Predicted'], index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
