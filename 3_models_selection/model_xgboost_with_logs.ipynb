{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T10:45:34.450826Z",
     "start_time": "2023-06-11T10:45:34.402158Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>data_channel</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://mashable.com/2014/09/08/safest-cabbies-...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.545031</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160714</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>bus</td>\n",
       "      <td>tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://mashable.com/2013/07/25/3d-printed-rifle/</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157500</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>tech</td>\n",
       "      <td>thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://mashable.com/2013/10/30/digital-dinosau...</td>\n",
       "      <td>435.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.646018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748428</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427500</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://mashable.com/2014/08/27/homer-simpson-i...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216667</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>bus</td>\n",
       "      <td>wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://mashable.com/2013/01/10/creepy-robotic-...</td>\n",
       "      <td>728.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251786</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>tech</td>\n",
       "      <td>thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                url  timedelta  \\\n",
       "0   0  http://mashable.com/2014/09/08/safest-cabbies-...      121.0   \n",
       "1   1   http://mashable.com/2013/07/25/3d-printed-rifle/      532.0   \n",
       "2   2  http://mashable.com/2013/10/30/digital-dinosau...      435.0   \n",
       "3   3  http://mashable.com/2014/08/27/homer-simpson-i...      134.0   \n",
       "4   4  http://mashable.com/2013/01/10/creepy-robotic-...      728.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0            1015.0         0.422018               1.0   \n",
       "1             9.0             503.0         0.569697               1.0   \n",
       "2             9.0             232.0         0.646018               1.0   \n",
       "3            12.0             171.0         0.722892               1.0   \n",
       "4            11.0             286.0         0.652632               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  ...  \\\n",
       "0                  0.545031       10.0             6.0  ...   \n",
       "1                  0.737542        9.0             0.0  ...   \n",
       "2                  0.748428       12.0             3.0  ...   \n",
       "3                  0.867925        9.0             5.0  ...   \n",
       "4                  0.800000        5.0             2.0  ...   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.160714                  -0.50              -0.071429   \n",
       "1              -0.157500                  -0.25              -0.100000   \n",
       "2              -0.427500                  -1.00              -0.187500   \n",
       "3              -0.216667                  -0.25              -0.166667   \n",
       "4              -0.251786                  -0.50              -0.100000   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 0.0                      0.00                     0.5   \n",
       "1                 0.0                      0.00                     0.5   \n",
       "2                 0.0                      0.00                     0.5   \n",
       "3                 0.4                     -0.25                     0.1   \n",
       "4                 0.2                     -0.10                     0.3   \n",
       "\n",
       "   abs_title_sentiment_polarity   shares  data_channel    weekday  \n",
       "0                          0.00   2900.0           bus    tuesday  \n",
       "1                          0.00   1300.0          tech   thursday  \n",
       "2                          0.00  17700.0     lifestyle  wednesday  \n",
       "3                          0.25   1500.0           bus  wednesday  \n",
       "4                          0.10   1400.0          tech   thursday  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_csv('../dataset/development.csv')\n",
    "df_eval = pd.read_csv('../dataset/evaluation.csv')\n",
    "\n",
    "df = pd.concat([df_dev, df_eval], sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31715, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T10:39:20.523112Z",
     "start_time": "2023-06-11T10:39:20.479647Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_preprocessing(df, reduce_df=True):\n",
    "    df_preproc = df.copy()\n",
    "\n",
    "    # one hot encoding\n",
    "    enc = OneHotEncoder()\n",
    "    encoded_df = pd.concat([df_preproc['weekday'], df_preproc['data_channel']], axis=1)\n",
    "    enc.fit(encoded_df)\n",
    "    encoded_df = enc.transform(encoded_df)\n",
    "    additional_columns = enc.get_feature_names_out()\n",
    "    df_preproc[additional_columns] = encoded_df.toarray()\n",
    "    df_preproc.drop(['weekday', 'data_channel', 'url', 'id'], axis = 1, inplace=True)\n",
    "\n",
    "    # drop from feature selection\n",
    "    df_preproc.drop(columns=['n_non_stop_words', 'kw_min_min', 'kw_max_max'], inplace=True)\n",
    "\n",
    "    if reduce_df:\n",
    "        # remove n_tokens_content less than 0\n",
    "        df_preproc = df_preproc.query(\"n_tokens_content > 0\")\n",
    "        df_preproc['n_tokens_content'] = np.log(df_preproc['n_tokens_content'])\n",
    "        # Remove outliers from kw_avg_avg (we lost another 9% of the dataset)\n",
    "        q1 = df_preproc['kw_avg_avg'].describe()['25%']\n",
    "        q3 = df_preproc['kw_avg_avg'].describe()['75%']\n",
    "        iqr = q3 - q1\n",
    "        min_kw_avg_avg = q1 - 1.5*iqr\n",
    "        max_kw_avg_avg = q3 + 1.5*iqr\n",
    "        df_preproc = df_preproc[(df_preproc.kw_avg_avg < max_kw_avg_avg) & (df_preproc.kw_avg_avg > min_kw_avg_avg)]\n",
    "    else:\n",
    "        df_preproc['n_tokens_content'] = np.log(1 + df_preproc['n_tokens_content'])\n",
    "\n",
    "    # adjust num_imgs, num_self_hrefs, num_videos, num_hrefs\n",
    "    df_preproc['num_imgs'].fillna(df_preproc['num_imgs'].mean(), inplace=True)\n",
    "    df_preproc['num_imgs'] = np.log(1 + df_preproc['num_imgs'])\n",
    "    df_preproc['num_self_hrefs'].fillna(df_preproc['num_self_hrefs'].mean(), inplace=True)\n",
    "    df_preproc['num_self_hrefs'] = np.log(1 + df_preproc['num_self_hrefs'])\n",
    "    df_preproc['num_videos'].fillna(df_preproc['num_videos'].mean(), inplace=True)\n",
    "    df_preproc['num_videos'] = np.log(1 + df_preproc['num_videos'])\n",
    "    df_preproc['num_hrefs'] = np.log(1 + df_preproc['num_hrefs'])\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['n_tokens_title', 'n_tokens_content']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['n_tokens_title', 'n_tokens_content']])\n",
    "    df_preproc[['n_tokens_title', 'n_tokens_content']] = scaled_features\n",
    "\n",
    "    df_preproc['avg_negative_polarity'] = df_preproc['avg_negative_polarity'].abs()\n",
    "\n",
    "    # Since this features has a range between [0, 10], we can apply a min max scaling\n",
    "    df_preproc['num_keywords'] = df.groupby(['data_channel'], sort=False)['num_keywords'].apply(lambda x: x.fillna(x.mean())).reset_index()['num_keywords']\n",
    "    std_scaler = MinMaxScaler().fit(df_preproc[['num_keywords']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['num_keywords']])\n",
    "    df_preproc[['num_keywords']] = scaled_features\n",
    "\n",
    "    if 'shares' in df_preproc:\n",
    "        df_preproc['shares'] = np.log(df_preproc['shares'])\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['kw_avg_max', 'kw_avg_avg', 'kw_avg_min', 'kw_min_avg', 'kw_max_avg', 'kw_max_min', 'kw_min_max']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['kw_avg_max', 'kw_avg_avg', 'kw_avg_min', 'kw_min_avg','kw_max_avg', 'kw_max_min', 'kw_min_max']])\n",
    "    df_preproc[['kw_avg_max', 'kw_avg_avg', 'kw_avg_min', 'kw_min_avg','kw_max_avg', 'kw_max_min', 'kw_min_max']] = scaled_features\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess']])\n",
    "    df_preproc[['self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess']] = scaled_features\n",
    "\n",
    "\n",
    "    is_weekend = []\n",
    "    for _, row in df_preproc.iterrows():\n",
    "        if row['weekday_sunday'] == 1 or row['weekday_saturday'] == 1:\n",
    "            is_weekend.append(1)\n",
    "        else:\n",
    "            is_weekend.append(0)\n",
    "    df_preproc['is_weekend'] = is_weekend\n",
    "\n",
    "    std_scaler = StandardScaler().fit(df_preproc[['timedelta']])\n",
    "    scaled_features = std_scaler.transform(df_preproc[['timedelta']])\n",
    "    df_preproc[['timedelta']] = scaled_features\n",
    "\n",
    "    return df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_355749/1438435930.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_preproc['n_tokens_content'] = np.log(df_preproc['n_tokens_content'])\n",
      "/var/tmp/ipykernel_355749/1438435930.py:46: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_preproc['num_keywords'] = df.groupby(['data_channel'], sort=False)['num_keywords'].apply(lambda x: x.fillna(x.mean())).reset_index()['num_keywords']\n",
      "/var/tmp/ipykernel_355749/1438435930.py:46: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_preproc['num_keywords'] = df.groupby(['data_channel'], sort=False)['num_keywords'].apply(lambda x: x.fillna(x.mean())).reset_index()['num_keywords']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7917, 7917)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df_dev = final_preprocessing(df_dev)\n",
    "df_working_df_eval = final_preprocessing(df_eval, reduce_df=False)\n",
    "(len(df_working_df_eval), len(df_eval))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = working_df_dev.drop(columns=[\"shares\"]).values\n",
    "y = working_df_dev[\"shares\"].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": ['reg:squarederror', 'reg:pseudohubererror'],\n",
    "    \"max_depth\": [4,7,8,10],\n",
    "    \"min_child_weight\": [3,5,7,9,12,15],\n",
    "    \"eta\": [0.001, 0.0025, 0.005, 0.01, 0.025, 0.05],\n",
    "    \"eval_metric\": [mean_squared_error],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print('MSE: %2.3f' % mse)\n",
    "    return mse\n",
    "\n",
    "def R2(y_true,y_pred):    \n",
    "     r2 = r2_score(y_true, y_pred)\n",
    "     adj_r2 = 1-(1-r2)*(len(X_valid) - 1)/(len(X_valid) - X_valid.shape[1] - 1)\n",
    "     print('R2: %2.3f' % adj_r2)\n",
    "     return adj_r2\n",
    "\n",
    "def two_score(y_true,y_pred):    \n",
    "    RMSE(y_true,y_pred) #set score here and not below if using MSE in GridCV\n",
    "    score = R2(y_true,y_pred)\n",
    "    return score\n",
    "\n",
    "def two_scorer():\n",
    "    return make_scorer(two_score, greater_is_better=False) # change for false if using MSE\n",
    "\n",
    "def rmse_scorer():\n",
    "    return make_scorer(RMSE, greater_is_better=False) # change for false if using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1639529628590907\n",
      "{'eta': 0.05, 'eval_metric': <function mean_squared_error at 0x7f29aca60820>, 'max_depth': 7, 'min_child_weight': 12, 'objective': 'reg:squarederror'}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(XGBRegressor(), param_grid=params, cv=5, scoring='r2')\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features has been used to train xgboost regressor and others. I tried also to decrease the number but the score decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814497689628405\n",
      "0.15743544269862797\n"
     ]
    }
   ],
   "source": [
    "rms = mean_squared_error(y_valid, gs.predict(X_valid), squared=False)\n",
    "print(rms)\n",
    "r2 = r2_score(y_valid, gs.predict(X_valid))\n",
    "adj_r2 = 1-(1-r2)*(len(X_valid) - 1)/(len(X_valid) - X_valid.shape[1] - 1)\n",
    "print(adj_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that for each of these models you can check the feature importance, so that remove some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data_channel_tech', 0.1563371),\n",
       " ('kw_avg_avg', 0.12027372),\n",
       " ('data_channel_socmed', 0.07851338),\n",
       " ('data_channel_entertainment', 0.07000306),\n",
       " ('is_weekend', 0.056433074),\n",
       " ('data_channel_lifestyle', 0.033759877),\n",
       " ('kw_min_avg', 0.033008665),\n",
       " ('data_channel_world', 0.03147098),\n",
       " ('num_hrefs', 0.026406191),\n",
       " ('min_positive_polarity', 0.025813013),\n",
       " ('global_subjectivity', 0.02474313),\n",
       " ('num_videos', 0.0245458),\n",
       " ('kw_avg_max', 0.024481896),\n",
       " ('num_imgs', 0.022690505),\n",
       " ('title_subjectivity', 0.022096708),\n",
       " ('title_sentiment_polarity', 0.021878142),\n",
       " ('global_sentiment_polarity', 0.021053853),\n",
       " ('n_tokens_content', 0.020581577),\n",
       " ('average_token_length', 0.020086395),\n",
       " ('global_rate_negative_words', 0.020071955),\n",
       " ('avg_negative_polarity', 0.02002607),\n",
       " ('n_non_stop_unique_tokens', 0.020018425),\n",
       " ('rate_negative_words', 0.019788092),\n",
       " ('avg_positive_polarity', 0.019588307),\n",
       " ('global_rate_positive_words', 0.01914742),\n",
       " ('max_positive_polarity', 0.018795239),\n",
       " ('num_keywords', 0.015723076),\n",
       " ('n_tokens_title', 0.012664358)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_names = working_df_dev.drop(columns=[\"shares\"]).columns\n",
    "# sorted(zip(feature_names, xgb_r.feature_importances_), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = working_df_dev.drop(columns=[\"shares\"]).values\n",
    "y = working_df_dev[\"shares\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[11:08:02] ../src/objective/objective.cc:26: Unknown objective function: `{'eta': 0.05, 'eval_metric': <function mean_squared_error at 0x7f29aca60820>, 'max_depth': 7, 'min_child_weight': 12}`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: reg:pseudohubererror\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\nObjective candidate: reg:absoluteerror\n\nStack trace:\n  [bt] (0) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x3708b3) [0x7f299bfeb8b3]\n  [bt] (1) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x370f8f) [0x7f299bfebf8f]\n  [bt] (2) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2e543c) [0x7f299bf6043c]\n  [bt] (3) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2ebfd7) [0x7f299bf66fd7]\n  [bt] (4) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2e02f8) [0x7f299bf5b2f8]\n  [bt] (5) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f299bdb75f0]\n  [bt] (6) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f29ebd57630]\n  [bt] (7) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f29ebd56fed]\n  [bt] (8) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x1084a) [0x7f29ebd6b84a]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gesposito/project/predict-shares-online-news/3_models_selection/model_xgboost_with_logs.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blegionlogin.polito.it/home/gesposito/project/predict-shares-online-news/3_models_selection/model_xgboost_with_logs.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m xgbr \u001b[39m=\u001b[39m XGBRegressor(gs\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blegionlogin.polito.it/home/gesposito/project/predict-shares-online-news/3_models_selection/model_xgboost_with_logs.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m xgbr\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [11:08:02] ../src/objective/objective.cc:26: Unknown objective function: `{'eta': 0.05, 'eval_metric': <function mean_squared_error at 0x7f29aca60820>, 'max_depth': 7, 'min_child_weight': 12}`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: reg:pseudohubererror\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\nObjective candidate: reg:absoluteerror\n\nStack trace:\n  [bt] (0) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x3708b3) [0x7f299bfeb8b3]\n  [bt] (1) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x370f8f) [0x7f299bfebf8f]\n  [bt] (2) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2e543c) [0x7f299bf6043c]\n  [bt] (3) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2ebfd7) [0x7f299bf66fd7]\n  [bt] (4) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x2e02f8) [0x7f299bf5b2f8]\n  [bt] (5) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f299bdb75f0]\n  [bt] (6) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f29ebd57630]\n  [bt] (7) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f29ebd56fed]\n  [bt] (8) /home/gesposito/miniconda3/envs/thesis/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x1084a) [0x7f29ebd6b84a]\n\n"
     ]
    }
   ],
   "source": [
    "xgbr = XGBRegressor(gs.best_params_)\n",
    "xgbr.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective candidate: survival:aft\n",
    "Objective candidate: binary:hinge\n",
    "Objective candidate: multi:softmax\n",
    "Objective candidate: multi:softprob\n",
    "Objective candidate: rank:pairwise\n",
    "Objective candidate: rank:ndcg\n",
    "Objective candidate: rank:map\n",
    "Objective candidate: reg:squarederror\n",
    "Objective candidate: reg:squaredlogerror\n",
    "Objective candidate: reg:logistic\n",
    "Objective candidate: binary:logistic\n",
    "Objective candidate: binary:logitraw\n",
    "Objective candidate: reg:linear\n",
    "Objective candidate: reg:pseudohubererror\n",
    "Objective candidate: count:poisson\n",
    "Objective candidate: survival:cox\n",
    "Objective candidate: reg:gamma\n",
    "Objective candidate: reg:tweedie\n",
    "Objective candidate: reg:absoluteerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final predictions\n",
    "y_pred = xgbr.predict(df_working_df_eval.values)\n",
    "final_preds = np.exp(y_pred)\n",
    "# Write CSV\n",
    "id_col = df_eval['id']\n",
    "new_df = pd.DataFrame(columns=['Id', 'Predicted'])\n",
    "new_df['Id'] = id_col\n",
    "new_df['Predicted'] = final_preds\n",
    "print(new_df.describe())\n",
    "new_df.to_csv('../output/output_xgboost_submit.csv', columns=['Id','Predicted'], index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the best configuration from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Id    Predicted\n",
      "count   7917.000000  7917.000000\n",
      "mean   35679.634584  1788.035156\n",
      "std     2289.051312   635.961304\n",
      "min    31715.000000   434.370697\n",
      "25%    33699.000000  1342.390991\n",
      "50%    35680.000000  1667.848267\n",
      "75%    37661.000000  2084.888916\n",
      "max    39643.000000  9050.632812\n"
     ]
    }
   ],
   "source": [
    "# Make final predictions\n",
    "y_pred = gs.predict(df_working_df_eval.values)\n",
    "final_preds = np.exp(y_pred)\n",
    "# Write CSV\n",
    "id_col = df_eval['id']\n",
    "new_df = pd.DataFrame(columns=['Id', 'Predicted'])\n",
    "new_df['Id'] = id_col\n",
    "new_df['Predicted'] = final_preds\n",
    "print(new_df.describe())\n",
    "new_df.to_csv('../output/NAME.csv', columns=['Id','Predicted'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
